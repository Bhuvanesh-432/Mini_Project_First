{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Title Rating    Votes Duration\n",
      "0               1. Anora    7.6   (160K)   2h 19m\n",
      "1       2. The Substance    7.3   (284K)   2h 21m\n",
      "2       3. The Brutalist    7.5    (71K)   3h 36m\n",
      "3            4. Conclave    7.4   (135K)       2h\n",
      "4  5. A Complete Unknown    7.4    (62K)   2h 21m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Start the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL to scrape (Updated to Action genre)\n",
    "url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=drama'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load completely\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul'))\n",
    ")\n",
    "\n",
    "titles = []\n",
    "ratings = []\n",
    "votings = []\n",
    "durations = []\n",
    "scraped_titles = set()  # This will store titles we've already scraped\n",
    "max_movies = 1000  # Limit the number of movies to scrape\n",
    "current_movie_count = 0  # Track how many movies we've scraped\n",
    "\n",
    "# Function to extract data\n",
    "def extract_data():\n",
    "    global current_movie_count  # Access the counter in the global scope\n",
    "    movie_items = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "    for movie_item in movie_items:\n",
    "        if current_movie_count >= max_movies:\n",
    "            return False  # Stop scraping once we've reached 1000 movies\n",
    "\n",
    "        try:\n",
    "            # Extract movie title\n",
    "            title = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "\n",
    "            # Skip if we've already scraped this title\n",
    "            if title in scraped_titles:\n",
    "                continue\n",
    "\n",
    "            # Extract rating, handle missing data gracefully\n",
    "            try:\n",
    "                rating = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[1]').text\n",
    "            except:\n",
    "                rating = \"N/A\"  # Default value for missing rating\n",
    "\n",
    "            # Extract voting, handle missing data gracefully\n",
    "            try:\n",
    "                voting = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[2]').text\n",
    "            except:\n",
    "                voting = \"N/A\"  # Default value for missing voting\n",
    "\n",
    "            # Extract duration if available, handle missing duration gracefully\n",
    "            try:\n",
    "                duration = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[2]/span[2]').text\n",
    "            except:\n",
    "                duration = \"N/A\"  # In case duration is missing\n",
    "\n",
    "            # Append data to respective lists\n",
    "            titles.append(title)\n",
    "            ratings.append(rating)\n",
    "            votings.append(voting)\n",
    "            durations.append(duration)\n",
    "\n",
    "            # Add the title to the set of scraped titles\n",
    "            scraped_titles.add(title)\n",
    "\n",
    "            # Increment the counter\n",
    "            current_movie_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting data for a movie: {e}\")\n",
    "            continue\n",
    "\n",
    "    return True\n",
    "\n",
    "# Extract data from the first page\n",
    "extract_data()\n",
    "\n",
    "# Function to click the '50 More' button safely\n",
    "def click_load_more():\n",
    "    try:\n",
    "        # Scroll to make sure the \"50 More\" button is in view\n",
    "        load_more_button = driver.find_element(By.XPATH, \"//*[@id='__next']/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button\")\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)\n",
    "\n",
    "        # Wait for the button to be clickable\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable(load_more_button))\n",
    "\n",
    "        # Use JavaScript to click the button (sometimes the default click doesn't work)\n",
    "        driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "        time.sleep(5)  # Wait for new content to load\n",
    "\n",
    "        # Extract new data\n",
    "        return extract_data()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. No more '50 More' button found or other issue.\")\n",
    "        return False\n",
    "\n",
    "# Click the \"50 More\" button until we've scraped 1000 movies\n",
    "while current_movie_count < max_movies:\n",
    "    if not click_load_more():\n",
    "        break\n",
    "\n",
    "# Close the driver after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the scraped data\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Rating': ratings,\n",
    "    'Votes': votings,\n",
    "    'Duration': durations\n",
    "})\n",
    "\n",
    "# Optionally save the data to a CSV file\n",
    "df.to_csv('drama_movies.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
